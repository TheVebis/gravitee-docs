[[event-native-apim-using]]
= Using Event-native API Management
:page-sidebar: apim_3_x_sidebar
:page-permalink: apim/3.x/event_native_apim_using.html
:page-folder: apim/event-native-apim
:page-layout: apim3x

[label label-version]#New in version 3.20.0#
[label label-version]#BETA release#

This page describes how to use event-native API management.

== Prerequisites

=== Kafka

These examples all depend on Kafka. To set up a Kafka Docker container with the link:https://github.com/tchiotludo/akhq[AKHQ] UI, follow these steps.

1. Download `link:https://raw.githubusercontent.com/tchiotludo/akhq/master/docker-compose.yml[docker-compose.yml]`.

2. Run it locally.
+
[source, bash]
----
docker-compose pull
docker-compose up
----

You can now access the AKHQ UI at http://localhost:8080.

===  Enabling event-native API management

To run these examples, you must set the `gravitee_api_jupiterMode_enabled` evnironment variable to `true` on the Management API and the API Gateway.

=== Postman Collections

These examples use the link:https://github.com/gravitee-io/postman-collections[Gravitee Postman Collections].

These collections use four variables.

[cols="1,1,1", options="header"]
|===
| Variable 
| Description 
| Example

| `management_host`
| The host for the Management API
| `http://localhost:8083` 

| `management_username`
| The username for a management user
| `admin`

| `management_password`
| The password for `management_username`
| 

| `gateway_host`
| The gateway host
| `http://loalhost:8082`
|===

== Data ingestion

For data ingestion, run the _01 - Data Ingestion_ Postman Collection.

You can also use `curl` to `POST` data to the endpoint.

[source bash]
----
curl -X POST -d "my_payload" http://localhost:8082/data/ingestion
----

== Event consumption

=== Streaming: server-sent events (SSE)

For streaming with server-sent events (SSE), run the _02 - Event Consumption - SSE_ Postman Collection.

You can test it with `curl`.

[source bash]
----
curl -N -H "Accept:text/event-stream" http://localhost:8082/demo/sse
----

=== Streaming: WebSocket

For streaming with WebSocket, run the _03 - Event Consumption - Websocket_ Postman Collection.

You can test it with Postman's WebSocket support, or you can use the `websocat` command-line tool.

[source bash]
----
websocat ws://localhost:8082/demo/ws
----

=== Webhooks

For webhooks, run the _04 - Event Consumption - Webhook_ Postman Collection.

This collection uses a webhook callback that is called by the API Gateway. The collection uses https://webhook.site/.

To use this collection, go to https://webhook.site/ to get your unique callback URL, and update the Postman Collection to use it. For example:

[source json]
----
{
    "configuration": {
        "type": "webhook",
        "callbackUrl": "https://webhook.site/891490b9-1e37-4b5e-8f91-4d40b9187710"
    }
}
----

==== Webhooks with cloud-events message format

Using webhooks with cloud-events message format is similar to using webhooks, but the message are formatted with the link:https://github.com/cloudevents/spec/blob/v1.0.2/cloudevents/formats/json-format.md[Cloud Events JSON format].

Use the following policy configuration.

[source json]
----
{
  "name": "Cloud Events",
  "description": "Transform to cloud-events message",
  "enabled": true,
  "policy": "cloud-events",
  "configuration": {
    "type": "demo-events",
    "id": "{#message.metadata['key']}",
    "source": "kafka://{#message.metadata['topic']}/{#message.metadata['partition']}/{#message.metadata['offset']}"
  }
}
----

==== Webhooks with subscription filter

For webhooks with subscription filters, run the _05 - Event Consumption - Webhook - Message Filtering_ Postman Collection.

Use the following policy configuration.

[source json]
----
{
  "name": "Message filtering",
  "description": "Apply filter to messages",
  "enabled": true,
  "policy": "message-filtering",
  "configuration": {
    "filter": "{#subscription.filter}"
  }
}
----